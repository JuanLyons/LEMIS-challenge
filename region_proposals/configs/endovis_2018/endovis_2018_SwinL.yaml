_BASE_: Base-COCO-EndoVis-InstanceSegmentation.yaml
MODEL:
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  WEIGHTS: "swin_large_patch4_window12_384_22k.pkl"
  # Keeping the original COCO means and stds provided better transfer learning results than using GraSP's
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 200
DATASETS:
  DATA_PATH: ""
  TRAIN: ("endovis-2018_train",)
  TEST: ("endovis-2018_test",)
SOLVER:
  IMS_PER_BATCH: 24
  BASE_LR: 0.0001
  # 1630 images
  # 68 iters per epoch 24 images per batch
  STEPS: (3022, 3274, 6044, 6548)
  MAX_ITER: 6800
  CHECKPOINT_PERIOD: 68
TEST:
  EVAL_PERIOD: 68


