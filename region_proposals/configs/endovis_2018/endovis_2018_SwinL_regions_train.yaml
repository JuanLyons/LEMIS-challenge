_BASE_: Base-COCO-EndoVis-InstanceSegmentation.yaml
MODEL:
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  WEIGHTS: "swin_large_patch4_window12_384_22k.pkl"
  # Keeping the original COCO means and stds provided better transfer learning results than using GraSP's
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 200
DATASETS:
  DATA_PATH: ""
  TRAIN: ("endovis-2018_train",)
  TEST: ("endovis-2018_test",)
SOLVER:
  IMS_PER_BATCH: 20
  BASE_LR: 0.00005
  STEPS: (3642, 3946, 7284, 7892)
  MAX_ITER: 8195
  CHECKPOINT_PERIOD: 82
TEST:
  EVAL_PERIOD: 82
DATASETS:
  TEST: ("endovis-2018_train",)